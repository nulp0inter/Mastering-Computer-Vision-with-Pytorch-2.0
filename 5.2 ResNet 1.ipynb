{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7835efc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/ava-orange-education/Mastering-Computer-Vision-with-PyTorch-2.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4547fcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet in PyTorch\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e164641d",
   "metadata": {},
   "source": [
    "<img src=\"images/Resnet.png\" width=1200 height=400/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341a6556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. THE RESIDUAL BLOCK\n",
    "# This is the building block. It does Conv -> BN -> ReLU -> Conv -> BN\n",
    "# Then it adds the original input (x) to the result before the final ReLU.\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        \n",
    "        # First Convolution\n",
    "        # in_channels, out_channels these are passed when called\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, \n",
    "                               stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        # Second Convolution\n",
    "         # in_channels, out_channels these are passed when called\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, \n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        # THE SHORTCUT (SKIP CONNECTION) LOGIC\n",
    "        # If the input size (x) doesn't match the output size (due to stride or channel change),\n",
    "        # we need to resize 'x' using a 1x1 convolution so we can add them together.\n",
    "        self.shortcut = nn.Sequential()#<-------------- This block executes in 2nd and 3rd block of above image \n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x  # Save the original input\n",
    "        \n",
    "        # Pass through the weight layers\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        \n",
    "        # --- THE MAGIC HAPPENS HERE ---\n",
    "        # Add the original input (identity) to the processed output\n",
    "        out += self.shortcut(identity) \n",
    "        # ------------------------------\n",
    "        \n",
    "        out = self.relu(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c115bed",
   "metadata": {},
   "source": [
    "<img src=\"images/Architecture.png\" width=1000 height=500 />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243b3b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. THE MAIN RESNET MODEL\n",
    "class SimpleResNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(SimpleResNet, self).__init__()\n",
    "        \n",
    "        # Initial processing (Input usually 3 channels for RGB)\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        # Stack the Residual Blocks\n",
    "        # Layer 1: Input 64 -> Output 64 (No size change)\n",
    "        self.layer1 = ResidualBlock(64, 64, stride=1)\n",
    "        # Layer 2: Input 64 -> Output 128 (Stride 2 cuts width/height in half)\n",
    "        self.layer2 = ResidualBlock(64, 128, stride=2)\n",
    "        # Layer 3: Input 128 -> Output 256\n",
    "        self.layer3 = ResidualBlock(128, 256, stride=2)\n",
    "        \n",
    "        # Final Classification\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1)) # Global Average Pooling\n",
    "        self.fc = nn.Linear(256, num_classes) # Fully Connected Layer, num_classes = 10\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Initial Block\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        # Residual/Sequential Layers\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        \n",
    "        # Final Classifier\n",
    "        out = self.avg_pool(out)\n",
    "        out = out.view(out.size(0), -1) # Flatten\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb8bbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. TEST IT\n",
    "# Create a random image: Batch size 1, 3 channels (RGB), 32x32 pixels\n",
    "dummy_input = torch.randn(1, 3, 32, 32)\n",
    "model = SimpleResNet(num_classes=10)\n",
    "output = model(dummy_input)\n",
    "\n",
    "print(f\"Input shape: {dummy_input.shape}\")\n",
    "print(f\"Output shape: {output.shape}\") # Should be [1, 10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
